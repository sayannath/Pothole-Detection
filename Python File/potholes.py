# -*- coding: utf-8 -*-
"""Potholes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dF10On_I13zRlQke8I6Sy0MzSgHhl1H9
"""

from google.colab import drive
drive.mount('/content/gdrive')

!unzip "/content/gdrive/My Drive/potholes.zip"

dataset_dir = 'potholes/'

import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from IPython.display import clear_output

import tensorflow as tf
import keras
from keras.optimizers import SGD, Adam, Adadelta
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization ,Dropout
from keras.models import Sequential
from keras.callbacks import Callback
from keras.preprocessing.image import ImageDataGenerator

print(tf.__version__)
print(keras.__version__)

dim1 = []
dim2 = []
for image_filename in os.listdir(dataset_dir+'/potholes'):
    
    img = mpimg.imread(dataset_dir+'/potholes'+'/'+image_filename)
    d1,d2,colors = img.shape
    dim1.append(d1)
    dim2.append(d2)

sns.jointplot(dim1,dim2)

print(np.mean(dim1))
print(np.mean(dim2))

class PlotLearning(Callback):
    def on_train_begin(self, logs={}):
        self.i = 0
        self.x = []
        self.losses = []
        self.val_losses = []
        self.acc = []
        self.val_acc = []
        self.fig = plt.figure()
        
        self.logs = []
        

    def on_epoch_end(self, epoch, logs={}):
        
        self.logs.append(logs)
        self.x.append(self.i)
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))
        self.acc.append(logs.get('accuracy'))
        self.val_acc.append(logs.get('val_accuracy'))
        self.i += 1
        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
        
        clear_output(wait=True)
        
        ax1.set_yscale('Log')
        ax1.plot(self.x, self.losses, label="loss")
        ax1.plot(self.x, self.val_losses, label="val_loss")
        ax1.legend()
        
        ax2.plot(self.x, self.acc, label="accuracy")
        ax2.plot(self.x, self.val_acc, label="val_accuracy")
        ax2.legend()
        
        plt.show()
        
        
plot = PlotLearning()

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.10, # Shift the pic width by a max of 5%
    height_shift_range=0.10, # Shift the pic height by a max of 5%
    rescale=1/255, # Rescale the image by normalzing it.
    shear_range=0.1, # Shear means cutting away part of the image (max 10%)
    zoom_range=0.1, # Zoom in by 10% max
    horizontal_flip=True, # Allow horizontal flipping
    fill_mode='nearest', # Fill in missing pixels with the nearest filled value
    validation_split=0.2,
)

train_gen = datagen.flow_from_directory(
    dataset_dir,
    target_size=(64,64),
    batch_size=32,
    color_mode='rgb',
    class_mode='binary',
    subset="training"
)

validation_gen = datagen.flow_from_directory(
    dataset_dir,
    target_size=(64,64),
    batch_size=32,
    class_mode='binary',
    color_mode='rgb',
    subset="validation"
)

model = Sequential()

model.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dense(1, activation='sigmoid'))


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()  # Summary of the model

model_history = model.fit(train_gen, steps_per_epoch=562, epochs=20, validation_data=validation_gen, callbacks=[plot])

plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.legend(['train', 'test'], loc='lower right')
plt.title('Accuracy plot - train vs test')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.show()

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.legend(['training loss', 'validation loss'], loc = 'upper right')
plt.title('Loss plot - training vs validation')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

model.save('potholes.h5')

print (train_gen.class_indices)

labels = '\n'.join(sorted(train_gen.class_indices.keys()))

with open('labels.txt', 'w') as f:
  f.write(labels)

new_model= tf.keras.models.load_model(filepath="potholes.h5")
tflite_converter = tf.lite.TFLiteConverter.from_keras_model(new_model)
tflite_model = tflite_converter.convert()
open("linear.tflite", "wb").write(tflite_model)

import numpy as np

from google.colab import files
from keras.preprocessing import image

uploaded=files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path='/content/' + fn
  img=image.load_img(path, target_size=(64, 64))
  
  x=image.img_to_array(img)
  x=np.expand_dims(x, axis=0)
  images = np.vstack([x])
  
  classes = model.predict(images, batch_size=32)
  
  print(classes)
  
  if classes[0]>0:
    print(fn + " is a pathole")
    
  else:
    print(fn + " is a normal")

